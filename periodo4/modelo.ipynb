{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n",
      "None\n",
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Carregar o dataset\n",
    "data = pd.read_csv('./creditcard.csv')\n",
    "\n",
    "# Verificar as primeiras linhas do dataset\n",
    "print(data.head())\n",
    "\n",
    "# Verificar as colunas e informações gerais\n",
    "print(data.info())\n",
    "\n",
    "# Verificar a distribuição das classes\n",
    "print(data['Class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar as features (X) e a label (y)\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Padronizar as features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir o dataset em treino (80%) e teste (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(input_size, hidden_size, output_size):\n",
    "    W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "    b1 = np.zeros((1, hidden_size))\n",
    "    W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "    b2 = np.zeros((1, output_size))\n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def backward_propagation(X, y, Z1, A1, Z2, A2, W1, W2):\n",
    "    m = X.shape[0]\n",
    "    dZ2 = A2 - y.reshape(-1, 1)\n",
    "    dW2 = np.dot(A1.T, dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "    dZ1 = np.dot(dZ2, W2.T) * sigmoid_derivative(Z1)\n",
    "    dW1 = np.dot(X.T, dZ1) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "    return dW1, db1, dW2, db2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mini_batch(X_train, y_train, hidden_size, epochs, learning_rate, batch_size):\n",
    "    input_size = X_train.shape[1]\n",
    "    output_size = 1\n",
    "    W1, b1, W2, b2 = initialize_weights(input_size, hidden_size, output_size)\n",
    "    \n",
    "    y_train = y_train.to_numpy()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        permutation = np.random.permutation(X_train.shape[0])\n",
    "        X_train_shuffled = X_train[permutation]\n",
    "        y_train_shuffled = y_train[permutation]\n",
    "        \n",
    "        total_cost = 0  # Inicializar o custo total para a época\n",
    "        \n",
    "        for i in range(0, X_train.shape[0], batch_size):\n",
    "            X_batch = X_train_shuffled[i:i+batch_size]\n",
    "            y_batch = y_train_shuffled[i:i+batch_size]\n",
    "            \n",
    "            Z1, A1, Z2, A2 = forward_propagation(X_batch, W1, b1, W2, b2)\n",
    "            dW1, db1, dW2, db2 = backward_propagation(X_batch, y_batch, Z1, A1, Z2, A2, W1, W2)\n",
    "            \n",
    "            W1 -= learning_rate * dW1\n",
    "            b1 -= learning_rate * db1\n",
    "            W2 -= learning_rate * dW2\n",
    "            b2 -= learning_rate * db2\n",
    "            \n",
    "            # Calcular o custo para o mini-batch atual e somar ao custo total\n",
    "            mini_batch_cost = -np.sum(y_batch * np.log(A2) + (1 - y_batch) * np.log(1 - A2)) / X_batch.shape[0]\n",
    "            total_cost += mini_batch_cost\n",
    "        \n",
    "        # Tirar a média do custo total para a época\n",
    "        avg_cost = total_cost / (X_train.shape[0] / batch_size)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Custo: {avg_cost}')\n",
    "    \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_propagation(X, W1, b1, W2, b2)\n",
    "    predictions = (A2 > 0.5).astype(int)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Custo: 1.0013804862484672\n",
      "Epoch 100, Custo: 0.565404118605539\n",
      "Epoch 200, Custo: 0.6178961276623987\n",
      "Epoch 300, Custo: 0.6464877010800132\n",
      "Epoch 400, Custo: 0.6667269437007781\n",
      "Epoch 500, Custo: 0.6805323896449155\n",
      "Epoch 600, Custo: 0.6903860444727661\n",
      "Epoch 700, Custo: 0.6926291711115676\n",
      "Epoch 800, Custo: 0.7114659191741732\n",
      "Epoch 900, Custo: 0.7230738475210856\n",
      "Acurácia: 0.9993679997191109\n",
      "Precisão: 0.8163265306122449\n",
      "Recall: 0.8163265306122449\n",
      "F1-Score: 0.8163265306122449\n",
      "Matriz de Confusão:\n",
      "[[56846    18]\n",
      " [   18    80]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Definir parâmetros de treinamento\n",
    "hidden_size = 10\n",
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "batch_size = 32  # Definir o tamanho do mini-batch\n",
    "\n",
    "# Treinar o modelo usando mini-batches\n",
    "W1, b1, W2, b2 = train_mini_batch(X_train, y_train, hidden_size, epochs, learning_rate, batch_size)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = predict(X_test, W1, b1, W2, b2)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# Avaliar o desempenho\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Acurácia: {accuracy}')\n",
    "print(f'Precisão: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-Score: {f1}')\n",
    "print('Matriz de Confusão:')\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Convergência do Modelo**\n",
    "\n",
    "Observa-se que o custo começou em aproximadamente 1.001 e diminuiu ao longo do treinamento, mas estabilizou e até aumentou levemente, chegando a 0.723. Isso pode sugerir que o modelo pode estar se aproximando de seu limite de aprendizagem, e o aumento do custo nas últimas épocas pode ser um indício de overfitting, especialmente se o custo nos dados de validação também estivesse aumentando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Desempenho do Modelo**\n",
    "- A acurácia é extremamente alta, quase 99.94%. Isso indica que o modelo está acertando a maioria das previsões, o que é esperado, dada a grande quantidade de exemplos da classe majoritária (não fraudulentos).\n",
    "\n",
    "- Precisão e o recall são de aproximadamente 81.6%. Isso é positivo, pois indica que, dos casos que o modelo previu como fraudulentos, 81.6% realmente eram fraudes\n",
    "\n",
    "- O F1-Score de 0.816 indica um bom equilíbrio entre precisão e recall.\n",
    "\n",
    "- A matriz de confusão mostra 80 fraudes corretamente identificadas e apenas 18 erros (falsos positivos e falsos negativos).\n",
    "\n",
    "- Apesar do alto desbalanceamento do dataset (com 284,315 transações não fraudulentas e apenas 492 fraudulentas), a boa precisão e recall mostram que o modelo conseguiu aprender a identificar fraudes, apesar desse desbalanceamento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
